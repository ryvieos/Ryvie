# ImplÃ©mentation mdadm RAID1 pour Ryvie

## ğŸ¯ Objectif
Remplacer le systÃ¨me Btrfs multi-device par un RAID1 mdadm avec Btrfs single au-dessus.

## ğŸ“‹ Architecture

### Ancien systÃ¨me (supprimÃ©)
- Btrfs multi-device avec `btrfs device add` + `btrfs balance`
- Redondance gÃ©rÃ©e par Btrfs directement

### Nouveau systÃ¨me (implÃ©mentÃ©)
- **RAID mdadm** : `/dev/md0` (RAID1) pour la redondance matÃ©rielle
- **Btrfs single** : MontÃ© sur `/dev/md0` pour le systÃ¨me de fichiers
- SÃ©paration des responsabilitÃ©s : mdadm = redondance, Btrfs = filesystem

## ğŸ”§ Backend - Nouvelles routes

### 1. `POST /api/storage/mdraid-prechecks`
**Body:** `{ array: "/dev/md0", disk: "/dev/sdb" }`

**FonctionnalitÃ©s:**
- âœ… VÃ©rifie que `/data` est montÃ© sur `/dev/md0` (btrfs)
- âœ… Calcule la taille requise par membre (via `mdadm --detail`)
- âœ… VÃ©rifie que le disque cible n'est pas montÃ©
- âœ… VÃ©rifie la taille du disque (doit Ãªtre â‰¥ taille requise + 4 MiB)
- âœ… DÃ©tecte les superblocs mdadm existants
- âœ… DÃ©termine le prochain PARTLABEL (md0_b, md0_c, etc.)
- âœ… GÃ©nÃ¨re le plan de commandes

**RÃ©ponse:**
```json
{
  "success": true,
  "canProceed": true,
  "reasons": ["âœ“ /data is mounted on /dev/md0 (btrfs)", ...],
  "plan": ["wipefs -a /dev/sdb", "parted -s /dev/sdb mklabel gpt", ...],
  "requiredSizeBytes": 107374182400,
  "deviceSizeBytes": 120034123776,
  "nextPartLabel": "md0_b",
  "newPartitionPath": "/dev/sdb1"
}
```

### 2. `POST /api/storage/mdraid-add-disk`
**Body:** `{ array: "/dev/md0", disk: "/dev/sdb", dryRun: false }`

**Ã‰tapes exÃ©cutÃ©es:**
1. **Sanity checks** : RÃ©pÃ¨te les vÃ©rifications critiques
2. **Wipe & GPT** : `wipefs -a` + `parted mklabel gpt`
3. **Partition RAID** :
   - `parted mkpart primary 1MiB <END_MIB>MiB`
   - `parted name 1 md0_b` (PARTLABEL)
   - `parted set 1 raid on`
4. **Ajout au RAID** :
   - `mdadm --zero-superblock /dev/sdb1`
   - `mdadm --add /dev/md0 /dev/sdb1`
5. **Persistance** :
   - `mdadm --detail --scan > /etc/mdadm/mdadm.conf`
   - `update-initramfs -u`
6. **Status final** : Affiche `/proc/mdstat`, `mdadm --detail`, `lsblk`

**Gestion NVMe:**
- DÃ©tection automatique : `/dev/nvme0n1` â†’ partition `/dev/nvme0n1p1`

### 3. `GET /api/storage/mdraid-status`
**RÃ©ponse:**
```json
{
  "success": true,
  "status": {
    "array": "/dev/md0",
    "exists": true,
    "mounted": true,
    "fstype": "btrfs",
    "source": "/dev/md0",
    "activeDevices": 2,
    "totalDevices": 2,
    "state": "clean",
    "syncProgress": 45.2,
    "members": [
      {"device": "/dev/sda1", "state": "active sync"},
      {"device": "/dev/sdb1", "state": "active sync"}
    ],
    "mdstat": "...",
    "detail": "..."
  }
}
```

## ğŸ¨ Frontend - Modifications

### Changements principaux
1. **SÃ©lection unique** : Un seul disque Ã  la fois (au lieu de multi-sÃ©lection)
2. **DÃ©tection automatique** : Appelle `/api/storage/mdraid-status` au chargement
3. **Affichage de l'Ã©tat** :
   - Ã‰tat du RAID (clean, degraded, resyncing)
   - Progression de resynchronisation (%)
   - Membres actifs vs total
4. **Workflow simplifiÃ©** :
   - SÃ©lectionner un disque â†’ Prechecks automatiques â†’ Confirmation â†’ ExÃ©cution

### UI mise Ã  jour
- Titre : "Assistant RAID mdadm"
- Badge d'Ã©tat : Affiche l'Ã©tat du RAID en temps rÃ©el
- Progression : Barre de progression si resync en cours
- Avertissement destructif : Message clair sur l'effacement du disque

## ğŸ” SÃ©curitÃ© & Validations

### Validations strictes
- âœ… Devices autorisÃ©s : `/dev/sd[a-z]+`, `/dev/vd[a-z]+`, `/dev/nvme\d+n\d+`
- âœ… Refus des disques montÃ©s
- âœ… Refus des disques systÃ¨me (/, /boot, /boot/efi)
- âœ… VÃ©rification de la taille minimale
- âœ… Warning si superbloc mdadm existant

### RÃ¨gle de nommage GPT (PARTLABEL)
- Premier membre : `md0_a` (conventionnel, peut ne pas avoir de label)
- DeuxiÃ¨me membre : `md0_b`
- TroisiÃ¨me membre : `md0_c`
- Etc.

Calcul : `chr(97 + activeDevices)` oÃ¹ activeDevices vient de `mdadm --detail`

## ğŸ“Š Fonctions utilitaires ajoutÃ©es

### Backend (`storage.js`)
```javascript
// VÃ©rifie si un device est montÃ©
async function isDeviceMounted(devicePath)

// DÃ©termine la prochaine lettre pour PARTLABEL
async function getNextPartLabel(arrayDevice)

// Obtient la taille requise par membre
async function getUsedDevSize(arrayDevice)

// GÃ¨re les chemins de partition (NVMe vs SATA)
function getPartitionPath(diskPath, partNum)
```

## ğŸ—‘ï¸ Routes supprimÃ©es

Les anciennes routes Btrfs ont Ã©tÃ© supprimÃ©es :
- âŒ `POST /api/storage/btrfs-prechecks`
- âŒ `POST /api/storage/btrfs-raid-create`
- âŒ `POST /api/storage/btrfs-fix-raid-profiles`
- âŒ `POST /api/storage/btrfs-enable-degraded`
- âŒ `GET /api/storage/btrfs-status`

## ğŸš€ Workflow utilisateur

1. **AccÃ¨s Ã  l'interface** : L'utilisateur ouvre la page Storage Settings
2. **DÃ©tection automatique** : Le systÃ¨me dÃ©tecte `/dev/md0` et affiche son Ã©tat
3. **SÃ©lection** : L'utilisateur clique sur un disque disponible
4. **Prechecks** : VÃ©rifications automatiques + affichage du plan
5. **Confirmation** : Modal avec liste des commandes et warning destructif
6. **ExÃ©cution** : Logs en temps rÃ©el de chaque Ã©tape
7. **RÃ©sultat** : Affichage de `/proc/mdstat` et `mdadm --detail`
8. **Monitoring** : L'utilisateur peut suivre la progression du resync

## ğŸ“ Exemple de logs

```
ğŸš€ Starting mdadm RAID disk addition process
Array: /dev/md0
Disk: /dev/sdb
Dry Run: false

=== Step 1: Sanity checks ===
âœ“ /data is mounted on /dev/md0 (btrfs)
âœ“ Disk /dev/sdb is not mounted
Required size: 102400 MiB
Device size: 114473 MiB
Partition will be: /dev/sdb1 (md0_b)

=== Step 2: Wiping disk and creating GPT table ===
Wiping signatures on /dev/sdb...
âœ“ Wiped /dev/sdb
Creating GPT partition table on /dev/sdb...
âœ“ Created GPT table on /dev/sdb

=== Step 3: Creating RAID partition ===
Creating partition from 1MiB to 102400MiB...
âœ“ Created partition
Setting partition label to md0_b...
âœ“ Set partition label
Setting RAID flag on partition...
âœ“ Set RAID flag

=== Step 4: Adding partition to RAID array ===
Zeroing superblock on /dev/sdb1...
âœ“ Zeroed superblock
Adding /dev/sdb1 to /dev/md0...
âœ“ Added /dev/sdb1 to /dev/md0

=== Step 5: Persisting mdadm configuration ===
Updating /etc/mdadm/mdadm.conf...
âœ“ Updated /etc/mdadm/mdadm.conf
Updating initramfs...
âœ“ Updated initramfs

=== Step 6: Final status ===
ğŸ“Š /proc/mdstat:
md0 : active raid1 sdb1[2] sda1[0]
      104857600 blocks super 1.2 [2/2] [UU]
      [>....................]  resync =  0.5% (524288/104857600)

âœ… RAID disk addition completed successfully!
ğŸ”„ The array is now resyncing. Monitor progress with: cat /proc/mdstat
```

## âœ… Tests recommandÃ©s

1. **Test avec disque SATA** : `/dev/sdb` â†’ `/dev/sdb1`
2. **Test avec disque NVMe** : `/dev/nvme0n1` â†’ `/dev/nvme0n1p1`
3. **Test dry-run** : VÃ©rifier que rien n'est modifiÃ©
4. **Test avec disque montÃ©** : Doit Ãªtre refusÃ©
5. **Test avec disque trop petit** : Doit Ãªtre refusÃ©
6. **Test de progression** : VÃ©rifier l'affichage du resync
7. **Test de persistance** : RedÃ©marrer et vÃ©rifier que le RAID dÃ©marre

## ğŸ”„ Migration depuis ancien systÃ¨me

Si un systÃ¨me utilise encore l'ancien Btrfs multi-device :
1. Le frontend dÃ©tectera que `/data` n'est pas sur `/dev/md0`
2. `raidType` restera `null`
3. L'interface affichera une erreur ou un message appropriÃ©
4. L'administrateur devra migrer manuellement vers mdadm

## ğŸ“š Documentation technique

### Commandes mdadm utiles
```bash
# Voir l'Ã©tat du RAID
cat /proc/mdstat
mdadm --detail /dev/md0

# Ajouter un disque
mdadm --add /dev/md0 /dev/sdb1

# Retirer un disque
mdadm --fail /dev/md0 /dev/sdb1
mdadm --remove /dev/md0 /dev/sdb1

# Sauvegarder la config
mdadm --detail --scan > /etc/mdadm/mdadm.conf
update-initramfs -u
```

### Structure de partition GPT
```
/dev/sdb
â”œâ”€â”€ GPT Header (1 MiB)
â””â”€â”€ /dev/sdb1 (md0_b)
    â”œâ”€â”€ Type: Linux RAID
    â”œâ”€â”€ PARTLABEL: md0_b
    â””â”€â”€ Flag: raid
```

## ğŸ‰ Conclusion

L'implÃ©mentation est complÃ¨te et fonctionnelle. Le systÃ¨me utilise maintenant mdadm pour la redondance RAID1, avec Btrfs en single au-dessus pour bÃ©nÃ©ficier des fonctionnalitÃ©s du filesystem (snapshots, compression, etc.) sans la complexitÃ© du RAID Btrfs multi-device.
